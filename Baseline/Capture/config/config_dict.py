

bert_config_json_dict = {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 21128,
  "v_feature_size": 2048,
  "v_target_size": 1601,
  "v_hidden_size": 1024,
  "v_num_hidden_layers":6,
  "v_num_attention_heads":8,
  "v_intermediate_size":1024,
  "bi_hidden_size":1024,
  "bi_num_attention_heads":8,
  "bi_intermediate_size": 1024,
  "bi_attention_type":1,
  "v_attention_probs_dropout_prob":0.1,
  "v_hidden_act":"gelu",
  "v_hidden_dropout_prob":0.1,
  "v_initializer_range":0.02,
  "v_biattention_id":[0, 1, 2, 3, 4, 5],
  "t_biattention_id":[6, 7, 8, 9, 10, 11],
  "pooling_method": "mul"
}

tb_feature_bert_config_json_dict = {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 21128,
  "v_feature_size": 512,
  "v_target_size": 1601,
  "v_hidden_size": 1024,
  "v_num_hidden_layers":6,
  "v_num_attention_heads":8,
  "v_intermediate_size":1024,
  "bi_hidden_size":1024,
  "bi_num_attention_heads":8,
  "bi_intermediate_size": 1024,
  "bi_attention_type":1,
  "v_attention_probs_dropout_prob":0.1,
  "v_hidden_act":"gelu",
  "v_hidden_dropout_prob":0.1,
  "v_initializer_range":0.02,
  "v_biattention_id":[0, 1, 2, 3, 4, 5],
  "t_biattention_id":[6, 7, 8, 9, 10, 11],
  "pooling_method": "mul"
}


capture_config_json_dict = {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 21128,
  "v_feature_size": 2048,
  "v_target_size": 2048,
  "v_hidden_size": 768,
  "v_num_hidden_layers":12,
  "v_num_attention_heads":8,
  "v_intermediate_size":1024,
  "bi_hidden_size":1024,
  "bi_num_attention_heads":8,
  "bi_intermediate_size": 1024,
  "bi_attention_type":1,
  "v_attention_probs_dropout_prob":0.1,
  "v_hidden_act":"gelu",
  "v_hidden_dropout_prob":0.1,
  "v_initializer_range":0.02,
  "v_biattention_id":[6, 7, 8, 9, 10, 11],
  "t_biattention_id":[6, 7, 8, 9, 10, 11],
  "pooling_method": "mul"
}

capture_config_json_dict_old = {
    "attention_probs_dropout_prob": 0.1,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "max_position_embeddings": 512,
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "type_vocab_size": 2,
    "vocab_size": 21128,
    "v_feature_size": 512,
    "v_target_size": 1601,
    "v_hidden_size": 768,
    "v_num_hidden_layers":12,
    "v_num_attention_heads":8,
    "v_intermediate_size":1024,
    "bi_hidden_size":1024,
    "bi_num_attention_heads":8,
    "bi_intermediate_size": 1024,
    "bi_attention_type":1,
    "v_attention_probs_dropout_prob":0.1,
    "v_hidden_act":"gelu",
    "v_hidden_dropout_prob":0.1,
    "v_initializer_range":0.02,
    "v_biattention_id":[6, 7, 8, 9, 10, 11],
    "t_biattention_id":[6, 7, 8, 9, 10, 11],
    "pooling_method": "mul"
}


bert_weight_name=["embeddings.word_embeddings.weight",
                  "embeddings.position_embeddings.weight",
                  "embeddings.token_type_embeddings.weight",
                  "embeddings.LayerNorm.weight",
                  "embeddings.LayerNorm.bias",
                  "encoder.layer.0.attention.self.query.weight",
                  "encoder.layer.0.attention.self.query.bias",
                  "encoder.layer.0.attention.self.key.weight",
                  "encoder.layer.0.attention.self.key.bias",
                  "encoder.layer.0.attention.self.value.weight",
                  "encoder.layer.0.attention.self.value.bias",
                  "encoder.layer.0.attention.output.dense.weight",
                  "encoder.layer.0.attention.output.dense.bias",
                  "encoder.layer.0.attention.output.LayerNorm.weight",
                  "encoder.layer.0.attention.output.LayerNorm.bias",
                  "encoder.layer.0.intermediate.dense.weight",
                  "encoder.layer.0.intermediate.dense.bias",
                  "encoder.layer.0.output.dense.weight",
                  "encoder.layer.0.output.dense.bias",
                  "encoder.layer.0.output.LayerNorm.weight",
                  "encoder.layer.0.output.LayerNorm.bias",
                  "encoder.layer.1.attention.self.query.weight",
                  "encoder.layer.1.attention.self.query.bias",
                  "encoder.layer.1.attention.self.key.weight",
                  "encoder.layer.1.attention.self.key.bias",
                  "encoder.layer.1.attention.self.value.weight",
                  "encoder.layer.1.attention.self.value.bias",
                  "encoder.layer.1.attention.output.dense.weight",
                  "encoder.layer.1.attention.output.dense.bias",
                  "encoder.layer.1.attention.output.LayerNorm.weight",
                  "encoder.layer.1.attention.output.LayerNorm.bias",
                  "encoder.layer.1.intermediate.dense.weight",
                  "encoder.layer.1.intermediate.dense.bias",
                  "encoder.layer.1.output.dense.weight",
                  "encoder.layer.1.output.dense.bias",
                  "encoder.layer.1.output.LayerNorm.weight",
                  "encoder.layer.1.output.LayerNorm.bias",
                  "encoder.layer.2.attention.self.query.weight",
                  "encoder.layer.2.attention.self.query.bias",
                  "encoder.layer.2.attention.self.key.weight",
                  "encoder.layer.2.attention.self.key.bias",
                  "encoder.layer.2.attention.self.value.weight",
                  "encoder.layer.2.attention.self.value.bias",
                  "encoder.layer.2.attention.output.dense.weight",
                  "encoder.layer.2.attention.output.dense.bias",
                  "encoder.layer.2.attention.output.LayerNorm.weight",
                  "encoder.layer.2.attention.output.LayerNorm.bias",
                  "encoder.layer.2.intermediate.dense.weight",
                  "encoder.layer.2.intermediate.dense.bias",
                  "encoder.layer.2.output.dense.weight",
                  "encoder.layer.2.output.dense.bias",
                  "encoder.layer.2.output.LayerNorm.weight",
                  "encoder.layer.2.output.LayerNorm.bias",
                  "encoder.layer.3.attention.self.query.weight",
                  "encoder.layer.3.attention.self.query.bias",
                  "encoder.layer.3.attention.self.key.weight",
                  "encoder.layer.3.attention.self.key.bias",
                  "encoder.layer.3.attention.self.value.weight",
                  "encoder.layer.3.attention.self.value.bias",
                  "encoder.layer.3.attention.output.dense.weight",
                  "encoder.layer.3.attention.output.dense.bias",
                  "encoder.layer.3.attention.output.LayerNorm.weight",
                  "encoder.layer.3.attention.output.LayerNorm.bias",
                  "encoder.layer.3.intermediate.dense.weight",
                  "encoder.layer.3.intermediate.dense.bias",
                  "encoder.layer.3.output.dense.weight",
                  "encoder.layer.3.output.dense.bias",
                  "encoder.layer.3.output.LayerNorm.weight",
                  "encoder.layer.3.output.LayerNorm.bias",
                  "encoder.layer.4.attention.self.query.weight",
                  "encoder.layer.4.attention.self.query.bias",
                  "encoder.layer.4.attention.self.key.weight",
                  "encoder.layer.4.attention.self.key.bias",
                  "encoder.layer.4.attention.self.value.weight",
                  "encoder.layer.4.attention.self.value.bias",
                  "encoder.layer.4.attention.output.dense.weight",
                  "encoder.layer.4.attention.output.dense.bias",
                  "encoder.layer.4.attention.output.LayerNorm.weight",
                  "encoder.layer.4.attention.output.LayerNorm.bias",
                  "encoder.layer.4.intermediate.dense.weight",
                  "encoder.layer.4.intermediate.dense.bias",
                  "encoder.layer.4.output.dense.weight",
                  "encoder.layer.4.output.dense.bias",
                  "encoder.layer.4.output.LayerNorm.weight",
                  "encoder.layer.4.output.LayerNorm.bias",
                  "encoder.layer.5.attention.self.query.weight",
                  "encoder.layer.5.attention.self.query.bias",
                  "encoder.layer.5.attention.self.key.weight",
                  "encoder.layer.5.attention.self.key.bias",
                  "encoder.layer.5.attention.self.value.weight",
                  "encoder.layer.5.attention.self.value.bias",
                  "encoder.layer.5.attention.output.dense.weight",
                  "encoder.layer.5.attention.output.dense.bias",
                  "encoder.layer.5.attention.output.LayerNorm.weight",
                  "encoder.layer.5.attention.output.LayerNorm.bias",
                  "encoder.layer.5.intermediate.dense.weight",
                  "encoder.layer.5.intermediate.dense.bias",
                  "encoder.layer.5.output.dense.weight",
                  "encoder.layer.5.output.dense.bias",
                  "encoder.layer.5.output.LayerNorm.weight",
                  "encoder.layer.5.output.LayerNorm.bias",
                  "encoder.layer.6.attention.self.query.weight",
                  "encoder.layer.6.attention.self.query.bias",
                  "encoder.layer.6.attention.self.key.weight",
                  "encoder.layer.6.attention.self.key.bias",
                  "encoder.layer.6.attention.self.value.weight",
                  "encoder.layer.6.attention.self.value.bias",
                  "encoder.layer.6.attention.output.dense.weight",
                  "encoder.layer.6.attention.output.dense.bias",
                  "encoder.layer.6.attention.output.LayerNorm.weight",
                  "encoder.layer.6.attention.output.LayerNorm.bias",
                  "encoder.layer.6.intermediate.dense.weight",
                  "encoder.layer.6.intermediate.dense.bias",
                  "encoder.layer.6.output.dense.weight",
                  "encoder.layer.6.output.dense.bias",
                  "encoder.layer.6.output.LayerNorm.weight",
                  "encoder.layer.6.output.LayerNorm.bias",
                  "encoder.layer.7.attention.self.query.weight",
                  "encoder.layer.7.attention.self.query.bias",
                  "encoder.layer.7.attention.self.key.weight",
                  "encoder.layer.7.attention.self.key.bias",
                  "encoder.layer.7.attention.self.value.weight",
                  "encoder.layer.7.attention.self.value.bias",
                  "encoder.layer.7.attention.output.dense.weight",
                  "encoder.layer.7.attention.output.dense.bias",
                  "encoder.layer.7.attention.output.LayerNorm.weight",
                  "encoder.layer.7.attention.output.LayerNorm.bias",
                  "encoder.layer.7.intermediate.dense.weight",
                  "encoder.layer.7.intermediate.dense.bias",
                  "encoder.layer.7.output.dense.weight",
                  "encoder.layer.7.output.dense.bias",
                  "encoder.layer.7.output.LayerNorm.weight",
                  "encoder.layer.7.output.LayerNorm.bias",
                  "encoder.layer.8.attention.self.query.weight",
                  "encoder.layer.8.attention.self.query.bias",
                  "encoder.layer.8.attention.self.key.weight",
                  "encoder.layer.8.attention.self.key.bias",
                  "encoder.layer.8.attention.self.value.weight",
                  "encoder.layer.8.attention.self.value.bias",
                  "encoder.layer.8.attention.output.dense.weight",
                  "encoder.layer.8.attention.output.dense.bias",
                  "encoder.layer.8.attention.output.LayerNorm.weight",
                  "encoder.layer.8.attention.output.LayerNorm.bias",
                  "encoder.layer.8.intermediate.dense.weight",
                  "encoder.layer.8.intermediate.dense.bias",
                  "encoder.layer.8.output.dense.weight",
                  "encoder.layer.8.output.dense.bias",
                  "encoder.layer.8.output.LayerNorm.weight",
                  "encoder.layer.8.output.LayerNorm.bias",
                  "encoder.layer.9.attention.self.query.weight",
                  "encoder.layer.9.attention.self.query.bias",
                  "encoder.layer.9.attention.self.key.weight",
                  "encoder.layer.9.attention.self.key.bias",
                  "encoder.layer.9.attention.self.value.weight",
                  "encoder.layer.9.attention.self.value.bias",
                  "encoder.layer.9.attention.output.dense.weight",
                  "encoder.layer.9.attention.output.dense.bias",
                  "encoder.layer.9.attention.output.LayerNorm.weight",
                  "encoder.layer.9.attention.output.LayerNorm.bias",
                  "encoder.layer.9.intermediate.dense.weight",
                  "encoder.layer.9.intermediate.dense.bias",
                  "encoder.layer.9.output.dense.weight",
                  "encoder.layer.9.output.dense.bias",
                  "encoder.layer.9.output.LayerNorm.weight",
                  "encoder.layer.9.output.LayerNorm.bias",
                  "encoder.layer.10.attention.self.query.weight",
                  "encoder.layer.10.attention.self.query.bias",
                  "encoder.layer.10.attention.self.key.weight",
                  "encoder.layer.10.attention.self.key.bias",
                  "encoder.layer.10.attention.self.value.weight",
                  "encoder.layer.10.attention.self.value.bias",
                  "encoder.layer.10.attention.output.dense.weight",
                  "encoder.layer.10.attention.output.dense.bias",
                  "encoder.layer.10.attention.output.LayerNorm.weight",
                  "encoder.layer.10.attention.output.LayerNorm.bias",
                  "encoder.layer.10.intermediate.dense.weight",
                  "encoder.layer.10.intermediate.dense.bias",
                  "encoder.layer.10.output.dense.weight",
                  "encoder.layer.10.output.dense.bias",
                  "encoder.layer.10.output.LayerNorm.weight",
                  "encoder.layer.10.output.LayerNorm.bias",
                  "encoder.layer.11.attention.self.query.weight",
                  "encoder.layer.11.attention.self.query.bias",
                  "encoder.layer.11.attention.self.key.weight",
                  "encoder.layer.11.attention.self.key.bias",
                  "encoder.layer.11.attention.self.value.weight",
                  "encoder.layer.11.attention.self.value.bias",
                  "encoder.layer.11.attention.output.dense.weight",
                  "encoder.layer.11.attention.output.dense.bias",
                  "encoder.layer.11.attention.output.LayerNorm.weight",
                  "encoder.layer.11.attention.output.LayerNorm.bias",
                  "encoder.layer.11.intermediate.dense.weight",
                  "encoder.layer.11.intermediate.dense.bias",
                  "encoder.layer.11.output.dense.weight",
                  "encoder.layer.11.output.dense.bias",
                  "encoder.layer.11.output.LayerNorm.weight",
                  "encoder.layer.11.output.LayerNorm.bias"]








